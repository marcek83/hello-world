{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wids_nlp_workshop.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcek83/hello-world/blob/master/wids_nlp_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "heXFC5w_46qS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# WIDS NLP Workshop\n",
        "\n",
        "## Doc2vec word embeddings and UMAP visualisation"
      ]
    },
    {
      "metadata": {
        "id": "2I4aTpNB_5o1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Setting up Google Colab**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nuE5pyMhzKr-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Installing PyDrive\n",
        "# PyDrive is a wrapper library of google-api-python-client.\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qLO8-smszSV9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-ZDtKu6zXKS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jU6iphJJzbKv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Add your ID for 'colab files' folder, e.g.: https://drive.google.com/open?id=1aBgO4hO6E6mcyU1u4hlYthOZXScNr0d5\n",
        "# List of your files on drive will be printed\n",
        "# E.g. twitter_trolls_english_only.csv, id: 1Ofl7U9qy3LFZ2XdxGXjZhOGBIC7JHsQx \n",
        "\n",
        "from google.colab import files\n",
        "file_list = drive.ListFile({'q': \"'YOUR FOLDER ID' in parents and trashed=false\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  print('title: %s, id: %s' % (file1['title'], file1['id']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rx-ncmn6z1Nt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Getting file content\n",
        "tweets_downloaded = drive.CreateFile({'id': 'YOUR FILE ID'})\n",
        "tweets_downloaded.GetContentFile('tweets_50k.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m_Zt10ldz91M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing Python libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "df1 = pd.read_csv('tweets_50k.csv', sep=',', engine='python')\n",
        "df1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tVKsIzD0rL29",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df1.count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JBJQZowlo5az",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kkmKBtPBnyIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Dropping tweets with null values\n",
        "df1 = df1.dropna(subset=['content'])\n",
        "df1 = df1.reset_index(drop = True)\n",
        "\n",
        "# Keep hold of original tweets and create a seperate column\n",
        "# for preprocessing and adding cleaned tweets\n",
        "df1['cleaned'] =  df1['content'].values\n",
        "\n",
        "## Removing emojis\n",
        "\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "\n",
        "def remove_emoji(df1):\n",
        "    row = list()\n",
        "    for i in range(0, df1.shape[0]):\n",
        "        if bool(re.search(emoji_pattern, df1['content'][i])) == True:\n",
        "            row.append(i)\n",
        "    df1.drop(df1.index[row], inplace=True)\n",
        "    return df1\n",
        "\n",
        "remove_emoji(df1)\n",
        "df1 = df1.reset_index(drop = True) # Resets the index when removing rows and does not add a  new column index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3qrL4UpImeQS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Removing stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "df1['cleaned'] = df1['cleaned'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pvp_sONXp2FI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Further pre-processing\n",
        "from nltk.stem.porter import *\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "# nltk.download() #run this first time to download all the packages in nltk\n",
        "\n",
        "from datetime import datetime \n",
        "from dateutil.parser import parse \n",
        "\n",
        "import string\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer, SnowballStemmer\n",
        "lemmatiser = WordNetLemmatizer()\n",
        "\n",
        "cleaned_tweet = []\n",
        "def cleantweet(df1, cleaned_tweet):\n",
        "    \n",
        "    for data in df1['cleaned']:\n",
        "        str_no_hyperlinks=re.sub(r'https?:\\/\\/.*\\/\\w*','',data)\n",
        "        str_lower =str_no_hyperlinks.lower()\n",
        "        str_letters_only = re.sub(\"[^a-zA-Z]\", \" \", str_lower) ##  remove non letters\n",
        "        str_no_username = re.sub(r'(?:@[\\w_]+)', '', str_letters_only) # @-mentions \n",
        "        str_no_username = str_no_username.strip()\n",
        "        exclude = set(string.punctuation)\n",
        "        str_no_punc = \"\".join(word for word in str_no_username if word not in exclude)\n",
        "        tweet = re.sub('[\\s]+', ' ', str_no_punc)\n",
        "        tweet1 = re.sub('[\\n]+', ' ', tweet)\n",
        "        tweets = re.sub(r'[^\\w]', ' ', tweet1)\n",
        "        #trim\n",
        "        tweets = tweets.strip()\n",
        "        cleaned_tweet.append(tweets)\n",
        "                  \n",
        "    return cleaned_tweet\n",
        "\n",
        "cleantweet(df1, cleaned_tweet)\n",
        "\n",
        "df1['cleaned'] = cleaned_tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X5XYWfTBsMQQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Keeping relevant columns only\n",
        "df = df1[['external_author_id', 'author', 'language','publish_date', 'cleaned', 'account_category']]\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZD8L1xBgsMnZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating account type dictionaries, we'll need them for umap\n",
        "account_types = {}\n",
        "for tweet in df.values:\n",
        "    try:\n",
        "        account_types[tweet[5].lower()]\n",
        "    except KeyError:\n",
        "        account_types[tweet[5].lower()] = []\n",
        "    account_types[tweet[5].lower()].append(tweet)\n",
        "unsorted_account_types_meta = []\n",
        "for key in account_types.keys():\n",
        "    unsorted_account_types_meta.append([key, len(account_types[key])])\n",
        "account_types_meta = sorted(unsorted_account_types_meta, key=lambda item: item[1])\n",
        "account_types_meta.reverse()\n",
        "for meta in account_types_meta:\n",
        "    print(meta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uz-01lcntamC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating authors dictionaries\n",
        "authors_dict = {}\n",
        "for tweet in df.values:\n",
        "    try:\n",
        "        authors_dict[tweet[0]]\n",
        "    except KeyError:\n",
        "        authors_dict[tweet[0]] = {'author_handle': tweet[1], 'account_type': tweet[5], 'tweet_bodies': []}\n",
        "    authors_dict[tweet[0]]['tweet_bodies'].append(tweet[4])\n",
        "authors = []\n",
        "for author_id, author_data in authors_dict.items():\n",
        "    authors.append({\n",
        "        'account_type': author_data['account_type'],\n",
        "        'author_handle': author_data['author_handle'],\n",
        "        'external_author_id': author_id,\n",
        "        'tweet_bodies': author_data['tweet_bodies'],\n",
        "        'tweets_count': len(author_data['tweet_bodies'])\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0CfJWm-Mta4M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "authors[:1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yeMEtjp6tq6V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Installing Gensim library for doc2vec\n",
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p3i7J0fxtrNI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from gensim.utils import simple_preprocess\n",
        "import logging\n",
        "import re\n",
        "\n",
        "class TaggedDocumentIterator:\n",
        "    def __iter__(self):\n",
        "        for i, author in enumerate(authors):\n",
        "            tweets_text = ''\n",
        "            for tweet_text in author['tweet_bodies']:\n",
        "                scrubbed_tweet_text = re.sub(r'\\bhttps://t\\.co/\\S*\\b', '', tweet_text)\n",
        "                tweets_text = tweets_text + ' ' + scrubbed_tweet_text\n",
        "            yield TaggedDocument(simple_preprocess(tweets_text), [i])\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "corpus = TaggedDocumentIterator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vGA3Ccydtrfa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Building vocabulary\n",
        "model = gensim.models.Doc2Vec(vector_size=200, min_count=5, epochs=10, workers=3)\n",
        "model.build_vocab(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n06BElB1truq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training model\n",
        "%time model.train(corpus, total_examples=model.corpus_count, epochs=model.epochs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QvHWN3_X23V5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Saving model\n",
        "model.save('doc2vec.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MX9tOIQhJFkZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Loading model\n",
        "from gensim.models.doc2vec import Doc2Vec\n",
        "d2v_model = Doc2Vec.load('doc2vec.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBRQwy-rJk5X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Printing the vector of document at index 1 in docLabels\n",
        "docvec = d2v_model.docvecs[1]\n",
        "print(docvec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q1BQk1LXKHF6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's see most similar document with similarity scores using document-index\n",
        "similar_doc = d2v_model.docvecs.most_similar(14) \n",
        "print(similar_doc)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YP6i0q6mLYM1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d2v_model.most_similar('trump')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OBumO3n8MLtn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "d2v_model.most_similar('gop')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PjqlR9WDtsBk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "docvecs = []\n",
        "for i in range(len(model.docvecs)):\n",
        "    docvecs.append(model.docvecs[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d9csrDBMtsR_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "docvecs[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VwpKbB0-uu8f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install umap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rd9l1PFNuvU0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mrOhqT0uwBj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import umap.umap_ as umap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aWxcWRujuwVC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding = umap.UMAP(verbose=True, random_state=42).fit_transform(docvecs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-FB6G3futbMH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "account_type_color_map = {\n",
        "    'righttroll': 'red',\n",
        "    'lefttroll': 'blue',\n",
        "    'fearmonger': 'black',\n",
        "    'hashtaggamer': 'purple',\n",
        "    'newsfeed': 'cyan',\n",
        "    'unknown': 'green',\n",
        "    'commercial': 'green',\n",
        "    'nonenglish': 'green'\n",
        "}\n",
        "\n",
        "% matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "c = []\n",
        "x = []\n",
        "y = []\n",
        "for i, item in enumerate(embedding):\n",
        "    c.append(account_type_color_map[authors[i]['account_type'].lower()])\n",
        "    x.append(item[0])\n",
        "    y.append(item[1])\n",
        "\n",
        "figumap = plt.figure(figsize=(10,10))\n",
        "plt.scatter(x, y, c=c, s=4, alpha=0.25)\n",
        "plt.show()\n",
        "#plt.savefig('fig_umap.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HjwffVZAvTYS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import cluster\n",
        "#from sklearn.cluster import KMeans\n",
        "n_clusters = 8\n",
        "k_means = cluster.KMeans(n_clusters=n_clusters, random_state=42)\n",
        "k_means.fit(docvecs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lAORsBbpvTwp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install bokeh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0oONL3PFvUHD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "% matplotlib inline\n",
        "from bokeh.palettes import Set2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "c = []\n",
        "x = []\n",
        "y = []\n",
        "for i, item in enumerate(embedding):\n",
        "    try:\n",
        "        c.append(Set2[n_clusters][k_means.labels_[i]])\n",
        "        x.append(item[0])\n",
        "        y.append(item[1])\n",
        "    except KeyError:\n",
        "        pass\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "all_patches = []\n",
        "for i in range(n_clusters):\n",
        "    all_patches.append(patches.Patch(color=Set2[n_clusters][i], label='Cluster ' + str(i)))\n",
        "plt.legend(handles=all_patches)\n",
        "plt.scatter(x, y, c=c, s=4, alpha=1)\n",
        "plt.title('Clusters on the 200-dimensional embeddings.')\n",
        "plt.show()\n",
        "#plt.savefig('bokeh_fig.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ctYXP_Svq-OS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G5frGaJ6q_KY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Doc2vec (DBOW & DM)**"
      ]
    },
    {
      "metadata": {
        "id": "WuTBQDvhvUZv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn import utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gensim\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import re\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rqnizr5uhCBB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_new = pd.read_csv('tweets_25k.csv', sep=',', engine='python')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zB9a_1j-hwRQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_new.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8efLAkaFW6Hu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_new = df_new[['content','account_category']]\n",
        "df_new = df_new[pd.notnull(df_new['content'])]\n",
        "df_new.rename(columns = {'content':'tweet'}, inplace = True)\n",
        "df_new.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "La541JtuW6ix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_new.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ddsy6RUdHtxs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_new['tweet'].apply(lambda x: len(x.split(' '))).sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "otZKXNH9ZLeO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cnt_pro = df_new['account_category'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "sns.barplot(cnt_pro.index, cnt_pro.values, alpha=0.8)\n",
        "plt.ylabel('Number of Occurrences', fontsize=12)\n",
        "plt.xlabel('Account_Category', fontsize=12)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qfEwEnnbaD8o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_tweet(index):\n",
        "    example = df_new[df_new.index == index][['tweet', 'account_category']].values[0]\n",
        "    if len(example) > 0:\n",
        "        print(example[0])\n",
        "        print('Account_Category:', example[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VtHu779EafBg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_tweet(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qdAr-M5yfy-5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_tweet(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nYVs9aN_P5TF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Text Processing"
      ]
    },
    {
      "metadata": {
        "id": "7S_Xz2bJaEVo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "def cleanText(text):\n",
        "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
        "    text = re.sub(r'http\\S+', r' ', text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "df1['tweet'] = df_new['tweet'].apply(cleanText)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2odxKnJWvH1j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "def tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text):\n",
        "        for word in nltk.word_tokenize(sent):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word.lower())\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1DBV9lm-vxdY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df_new, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3-oOGWz_ZL7O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_tagged = train.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['tweet']), tags=[r.account_category]), axis=1)\n",
        "test_tagged = test.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['tweet']), tags=[r.account_category]), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s0peCyrXZMPu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_tagged.values[20]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3M80tw6YQM3S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ]
    },
    {
      "metadata": {
        "id": "GDNhsdZNQffN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "DBOW"
      ]
    },
    {
      "metadata": {
        "id": "MeTNS2nEQvWo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Building a vocabulary"
      ]
    },
    {
      "metadata": {
        "id": "Vc8itqVBvVCA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_dbow = Doc2Vec(dm=0, vector_size=200, negative=5, hs=0, min_count=2, sample = 0, workers=2)\n",
        "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4byNqD-tweAE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(30):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
        "    model_dbow.alpha -= 0.002\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eEIajB-KQ-cN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Buliding the final vector feature for the classifier"
      ]
    },
    {
      "metadata": {
        "id": "G6m3Zlx1weh-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def vec_for_learning(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
        "    return targets, regressors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "APJOsTArwyNO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Raa3KmswyxM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJp3L__VwzU8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A4XbTbT2nVAC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('modeldbow.model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "43XWTSvWwzwT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import Doc2Vec \n",
        "model = Doc2Vec.load('modeldbow.model')\n",
        "docvecs = []\n",
        "for i in range(len(model.docvecs)):\n",
        "    docvecs.append(model.docvecs[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jkjc-MkP2aUr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "docvecs = []\n",
        "for i in range(len(model.docvecs)):\n",
        "    docvecs.append(model.docvecs[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cbs_Iu8o2hJv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "docvecs[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XT3Q8E1K0jse",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install umap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OcpgO-iG0uve",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install umap-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E1viWcwa3gVf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import umap.umap_ as umap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "myh5rbCiw0Pt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import umap\n",
        "embedding = umap.UMAP(verbose=True, random_state=42).fit_transform(docvecs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_grYIlqTwfA2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "account_types = {}\n",
        "for tweet in df_new.values:\n",
        "    try:\n",
        "        account_types[tweet[1].lower()]\n",
        "    except KeyError:\n",
        "        account_types[tweet[1].lower()] = []\n",
        "    account_types[tweet[1].lower()].append(tweet)\n",
        "unsorted_account_types_meta = []\n",
        "for key in account_types.keys():\n",
        "    unsorted_account_types_meta.append([key, len(account_types[key])])\n",
        "account_types_meta = sorted(unsorted_account_types_meta, key=lambda item: item[1])\n",
        "account_types_meta.reverse()\n",
        "for meta in account_types_meta:\n",
        "    print(meta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rIKL2Zqnwfr4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "authors_dict = {}\n",
        "for tweet in df_new.values:\n",
        "    try:\n",
        "        authors_dict[tweet[0]]\n",
        "    except KeyError:\n",
        "        authors_dict[tweet[0]] = {'account_type': tweet[1], 'tweet_bodies': []}\n",
        "    authors_dict[tweet[0]]['tweet_bodies'].append(tweet[0])\n",
        "authors = []\n",
        "for author_id, author_data in authors_dict.items():\n",
        "    authors.append({\n",
        "        'account_type': author_data['account_type'],\n",
        "        'tweet_bodies': author_data['tweet_bodies'],\n",
        "        'tweets_count': len(author_data['tweet_bodies'])\n",
        "    })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IuFSZG8X5UHc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "account_type_color_map = {\n",
        "    'righttroll': 'red',\n",
        "    'lefttroll': 'blue',\n",
        "    'fearmonger': 'black',\n",
        "    'hashtaggamer': 'purple',\n",
        "    'newsfeed': 'cyan',\n",
        "    'unknown': 'green',\n",
        "    'commercial': 'green',\n",
        "    'nonenglish': 'green'\n",
        "}\n",
        "\n",
        "% matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "c = []\n",
        "x = []\n",
        "y = []\n",
        "for i, item in enumerate(embedding):\n",
        "    c.append(account_type_color_map[authors[i]['account_type'].lower()])\n",
        "    x.append(item[0])\n",
        "    y.append(item[1])\n",
        "\n",
        "figumap = plt.figure(figsize=(10,10))\n",
        "plt.scatter(x, y, c=c, s=4, alpha=0.25)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0lfdXR1X6Sm9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import cluster\n",
        "#from sklearn.cluster import KMeans\n",
        "n_clusters = 8\n",
        "k_means = cluster.KMeans(n_clusters=n_clusters, random_state=42)\n",
        "k_means.fit(docvecs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kAcimkWllwZb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Visualisation with Bokeh"
      ]
    },
    {
      "metadata": {
        "id": "NJH-AYQz6TY6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install bokeh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GpzT3KUI6VGR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "% matplotlib inline\n",
        "hfrom bokeh.palettes import Set2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "c = []\n",
        "x = []\n",
        "y = []\n",
        "for i, item in enumerate(embedding):\n",
        "    try:\n",
        "        c.append(Set2[n_clusters][k_means.labels_[i]])\n",
        "        x.append(item[0])\n",
        "        y.append(item[1])\n",
        "    except KeyError:\n",
        "        pass\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "all_patches = []\n",
        "for i in range(n_clusters):\n",
        "    all_patches.append(patches.Patch(color=Set2[n_clusters][i], label='Cluster ' + str(i)))\n",
        "plt.legend(handles=all_patches)\n",
        "plt.scatter(x, y, c=c, s=4, alpha=1)\n",
        "plt.title('Clusters on the 200-dimensional embeddings.')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vexKYbf7OntZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Distributed Memory\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "leqW7-KC6Um-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
        "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "clUbFhuv6ULO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(30):\n",
        "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
        "    model_dmm.alpha -= 0.002\n",
        "    model_dmm.min_alpha = model_dmm.alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oEAcvxhNRX-J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "1HPdv0u-O_Y8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\n",
        "\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HD_LojOiO_vl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
        "model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eVGx6Ks0PAIw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
        "new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dcEVzanrPAdo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_vectors(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
        "    return targets, regressors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "412ZmkrqPA2q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train, X_train = get_vectors(new_model, train_tagged)\n",
        "y_test, X_test = get_vectors(new_model, test_tagged)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sdZZfMi4PWr8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "\n",
        "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZm91b_iPXEt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Lsl5g09PXmg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zZ6UsQbiPYGy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JBTnXzp-PX8C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtXoUbNjtbth",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ajL4YruRscXd",
        "colab_type": "code",
        "outputId": "0fdaf07f-6d78-4c38-9679-da020e7d8a91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "authors_dict = {}\n",
        "for tweet in df.values:\n",
        "    try:\n",
        "        authors_dict[tweet[0]]\n",
        "    except KeyError:\n",
        "        authors_dict[tweet[0]] = {'author_handle': tweet[1], 'account_type': tweet[5], 'tweet_text': []}\n",
        "    authors_dict[tweet[0]]['tweet_text'].append(tweet[4])\n",
        "authors = []\n",
        "for author_id, author_data in authors_dict.items():\n",
        "    authors.append({\n",
        "        'account_type': author_data['account_type'],\n",
        "        'author_handle': author_data['author_handle'],\n",
        "        'external_author_id': author_id,\n",
        "        'tweet_text': author_data['tweet_text'],\n",
        "        'tweets_count': len(author_data['tweet_text'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-622318763b9b>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    'tweets_count': len(author_data['tweet_text'])\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qkB9cT_9scsh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45wyIuwWsc_B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ach-lfNfsM8N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}